{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'autogen-agentchat==0.4.0.dev8' -qU\n",
    "%pip install 'autogen-ext[openai,azure]==0.4.0.dev8' -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../../.env\")\n",
    "os.environ.get(\"AZURE_OPENAI_ENDPOINT_GPT_4o\")\n",
    "\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY_GPT_4o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "AutoGen AgentChat provides a set of preset Agents, each with variations in how an agent might respond to messages. \n",
    "All agents share the following attributes and methods:\n",
    "\n",
    "- `name`: The unique name of the agent.\n",
    "- `description`: The description of the agent in text.\n",
    "- `on_messages()`: Send the agent a sequence of ChatMessage get a Response.\n",
    "- `on_messages_stream()`: Same as on_messages() but returns an iterator of AgentMessage followed by a Response as the last item.\n",
    "- `on_reset()`: Reset the agent to its initial state.\n",
    "\n",
    "See `autogen_agentchat.messages` for more information on AgentChat message types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_ext.models import AzureOpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "# Define a tool that searches the web for information.\n",
    "async def web_search(query: str) -> str:\n",
    "    \"\"\"Find information on the web\"\"\"\n",
    "    return \"AutoGen is a programming framework for building multi-agent applications.\"\n",
    "\n",
    "\n",
    "# Create an agent that uses the OpenAI GPT-4o model.\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint='https://xulei-omni.openai.azure.com',\n",
    "    model=\"gpt-4o\",\n",
    "    azure_deployment=\"gpt-4o-lei\",\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assistant_run() -> None:\n",
    "    response = await agent.on_messages(\n",
    "        [\n",
    "            TextMessage(content=\"Hello\", source=\"user\"),\n",
    "            TextMessage(content=\"Find information on AutoGen\", source=\"user\")\n",
    "        ],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    print(response.inner_messages)\n",
    "    print(response.chat_message)\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run()) when running in a script.\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Messages\n",
    "We can also stream each message as it is generated by the agent by using the `on_messages_stream()` method, and use Console to print the messages as they appear to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.task import Console\n",
    "\n",
    "\n",
    "async def assistant_run_stream() -> None:\n",
    "    # Option 1: read each message from the stream.\n",
    "    # async for message in agent.on_messages_stream(\n",
    "    #     [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "    #     cancellation_token=CancellationToken(),\n",
    "    # ):\n",
    "    #     print(message)\n",
    "\n",
    "    # Option 2: use Console to print all messages as they appear.\n",
    "    await Console(\n",
    "        agent.on_messages_stream(\n",
    "            [TextMessage(content=\"Find information on AutoGen\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run_stream()) when running in a script.\n",
    "await assistant_run_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on_messages_stream()` method returns an asynchronous generator that yields each inner message generated by the agent, and the last item is the final response message in the `chat_message` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Preset Agents\n",
    "The following preset agents are available:\n",
    "\n",
    "- `CodeExecutorAgent`: An agent that can execute code.\n",
    "- `OpenAIAssistantAgent`: An agent that is backed by an OpenAI Assistant, with ability to use custom tools.\n",
    "- `MultimodalWebSurfer`: A multi-modal agent that can search the web and visit web pages for information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
