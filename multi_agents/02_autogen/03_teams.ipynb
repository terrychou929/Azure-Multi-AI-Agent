{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'autogen-agentchat==0.4.0.dev8' -qU\n",
    "%pip install 'autogen-ext[openai,azure]==0.4.0.dev8' -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../../.env\")\n",
    "os.environ.get(\"AZURE_OPENAI_ENDPOINT_GPT_4o\")\n",
    "\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY_GPT_4o\"]\n",
    "api_base = os.environ[\"AZURE_OPENAI_ENDPOINT_GPT_4o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-Robin Group Chat\n",
    "`RoundRobinGroupChat` is a simple team that allows all agents to share context and take turns to respond in a round-robin fashion. \n",
    "\n",
    "On its turn, each agent broadcasts its response to all other agents in the team, so **all agents have the same context**.\n",
    "\n",
    "We will start by creating a team with a single AssistantAgent agent and TextMentionTermination termination condition that stops the team when a word is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.task import TextMentionTermination\n",
    "from autogen_ext.models import AzureOpenAIChatCompletionClient\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=api_base,\n",
    "    model=\"gpt-4o\",\n",
    "    azure_deployment=\"gpt-4o-lei\",\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")\n",
    "\n",
    "\n",
    "# Define a tool that gets the weather for a city.\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a city.\"\"\"\n",
    "    return f\"The weather in {city} is 72 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "# Create an assistant agent.\n",
    "weather_agent = AssistantAgent(\n",
    "    \"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"Respond 'TERMINATE' when task is complete.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition.\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "# Create a single-agent team.\n",
    "single_agent_team = RoundRobinGroupChat([weather_agent], termination_condition=text_termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_team() -> None:\n",
    "    result = await single_agent_team.run(task=\"What is the weather in New York?\")\n",
    "    print(result)\n",
    "\n",
    "\n",
    "# Use `asyncio.run(run_team())` when running in a script.\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "await single_agent_team.reset()  # Reset the team for the next run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Team Messages\n",
    "Similar to agent’s `on_messages_stream()` method, you can stream the team’s messages by calling the `run_stream()` method. \n",
    "\n",
    "It will return a generator that yields the messages produced by the agents in the team as they are generated, and the last item will be the task result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "\n",
    "async def run_team_stream() -> None:\n",
    "    async for message in single_agent_team.run_stream(task=\"What is the weather in New York?\"):\n",
    "        if isinstance(message, TaskResult):\n",
    "            print(\"Stop Reason:\", message.stop_reason)\n",
    "        else:\n",
    "            print(message)\n",
    "\n",
    "\n",
    "# Use `asyncio.run(run_team_stream())` when running in a script.\n",
    "await run_team_stream()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on_messages_stream()` method returns an asynchronous generator that yields each inner message generated by the agent, and the last item is the final response message in the `chat_message` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.task import Console\n",
    "\n",
    "# Use `asyncio.run(single_agent_team.reset())` when running in a script.\n",
    "await single_agent_team.reset()  # Reset the team for the next run.\n",
    "# Use `asyncio.run(single_agent_team.run_stream(task=\"What is the weather in Seattle?\"))` when running in a script.\n",
    "await Console(\n",
    "    single_agent_team.run_stream(task=\"What is the weather in Seattle?\")\n",
    ")  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Pattern\n",
    "Now we will create a team with two agents that implements the Reflection pattern, which is a multi-agent design pattern that uses a critic agent to evaluate the responses of a primary agent.\n",
    "\n",
    "See how the reflection pattern works using the Core API.\n",
    "\n",
    "In this example, we will use the `AssistantAgent` agent class for both the primary and critic agents. We will use both the `TextMentionTermination` and `MaxMessageTermination` termination conditions together to stop the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.task import MaxMessageTermination, TextMentionTermination\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=api_base,\n",
    "    model=\"gpt-4o\",\n",
    "    azure_deployment=\"gpt-4o-lei\",\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that stops the task if the critic approves.\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "# Define a termination condition that stops the task after 5 messages.\n",
    "max_message_termination = MaxMessageTermination(5)\n",
    "# Combine the termination conditions using the `|`` operator so that the\n",
    "# task stops when either condition is met.\n",
    "termination = text_termination | max_message_termination\n",
    "\n",
    "# Create a team with the primary and critic agents.\n",
    "reflection_team = RoundRobinGroupChat(\n",
    "    [primary_agent, critic_agent], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `asyncio.run(Console(reflection_team.run_stream(task=\"Write a short poem about fall season.\")))` when running in a script.\n",
    "await Console(\n",
    "    reflection_team.run_stream(task=\"Write a short poem about fall season.\")\n",
    ")  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming Team\n",
    "Let’s run the team again with a new task while keeping the context about the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the poem in Chinese Tang poetry style.\n",
    "# Use `asyncio.run(Console(reflection_team.run_stream(task=\"将这首诗用中文唐诗风格写一遍。\")))` when running in a script.\n",
    "await Console(reflection_team.run_stream(task=\"将这首诗用中文唐诗风格写一遍。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the poem in Spanish.\n",
    "# Use `asyncio.run(Console(reflection_team.run_stream(task=\"Write the poem in Spanish.\")))` when running in a script.\n",
    "await Console(reflection_team.run_stream(task=\"Write the poem in Spanish.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming A Previous Task\n",
    "We can call `run()` or `run_stream()` methods without setting the task again to resume the previous task. The team will continue from where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `asyncio.run(Console(reflection_team.run_stream()))` when running in a script.\n",
    "await Console(reflection_team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pause for User Input\n",
    "Often times, team needs additional input from the application (i.e., user) to continue processing the task. We will show two possible ways to do it:\n",
    "\n",
    "- Set the maximum number of turns such that the team stops after the specified number of turns.\n",
    "\n",
    "- Use the `HandoffTermination` termination condition.\n",
    "\n",
    "You can also use custom termination conditions, see Termination Conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Number of Turns\n",
    "This is the simplest way to pause the team for user input. For example, you can set the maximum number of turns to 1 such that the team stops right after the first agent responds. This is useful when you want the user to constantly engage with the team, such as in a chatbot scenario.\n",
    "\n",
    "Simply set the `max_turns` parameter in the `RoundRobinGroupChat()` constructor.\n",
    "\n",
    "```python\n",
    "team = RoundRobinGroupChat([...], max_turns=1)\n",
    "```\n",
    "\n",
    "Once the team stops, the turn count will be reset. When you resume the team, it will start from 0 again.\n",
    "\n",
    "Note that `max_turn` is specific to the team class and is currently only supported by `RoundRobinGroupChat`, `SelectorGroupChat`, and `Swarm`. When used with termination conditions, the team will stop when either condition is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Handoff to Pause Team\n",
    "You can use the `HandoffTermination` termination condition to stop the team when an agent sends a `HandoffMessage` message.\n",
    "\n",
    "Let’s create a team with a single `AssistantAgent` agent with a handoff setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.agents import AssistantAgent, Handoff\n",
    "from autogen_ext.models import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.task import HandoffTermination, TextMentionTermination\n",
    "\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=api_base,\n",
    "    model=\"gpt-4o\",\n",
    "    azure_deployment=\"gpt-4o-lei\",\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-06-01\"\n",
    ")\n",
    "\n",
    "# Create a lazy assistant agent that always hands off to the user.\n",
    "lazy_agent = AssistantAgent(\n",
    "    \"lazy_assistant\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[Handoff(target=\"user\", message=\"Transfer to user.\")],\n",
    "    system_message=\"Always transfer to user when you don't know the answer. Respond 'TERMINATE' when task is complete.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that checks for handoff message targetting helper and text \"TERMINATE\".\n",
    "handoff_termination = HandoffTermination(target=\"user\")\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination = handoff_termination | text_termination\n",
    "\n",
    "# Create a single-agent team.\n",
    "lazy_agent_team = RoundRobinGroupChat(\n",
    "    [lazy_agent], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.task import Console\n",
    "\n",
    "# Use `asyncio.run(Console(lazy_agent_team.run_stream(task=\"What is the weather in New York?\")))` when running in a script.\n",
    "await Console(lazy_agent_team.run_stream(task=\"What is the weather in New York?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `asyncio.run(Console(lazy_agent_team.run_stream(task=\"It is raining in New York.\")))` when running in a script.\n",
    "await Console(lazy_agent_team.run_stream(task=\"It is raining in New York.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
