{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 4: Data Analyzer\n",
    "**`Data Analyzer`** is an agent focused on data analysis, responsible for extracting valuable information from structured data (such as CSV files exported from databases), supporting two main tasks:\n",
    "\n",
    "1. **Anomaly Detection**: Identifying potential anomalous events in network security (such as abnormal traffic, unauthorized access, or attack behaviors).\n",
    "2. **Trend Prediction**: Predicting future security situations based on historical data (such as attack frequency trends, network traffic changes, and potential threat activity).\n",
    "\n",
    "Working in conjunction with **TimeGPT** (time series analysis tool), **Data Analyzer** can generate intuitive analysis results and return them in visual or data format to assist with network security decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define user tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terry_chou/Documents/trend-ai-workshop/TrendMicro_workshop_v2/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Any, Optional, Literal, Set, Callable\n",
    "from nixtla import NixtlaClient\n",
    "\n",
    "\n",
    "def analyze_data(file_path: str,\n",
    "                 method: Literal['forecast', 'anomaly_detection'],\n",
    "                 horizon: Optional[int] = 0,\n",
    "                 ftSteps: Optional[int] = 0) -> str:\n",
    "    \"\"\"\n",
    "    Analyze a dataset using the specified analysis method (forecasting or anomaly detection).\n",
    "\n",
    "    This function reads a pre-defined dataset based on the provided `file_name` argument, \n",
    "    performs the selected analysis method (`forecast` or `anomaly_detection`), and \n",
    "    returns the results in JSON format. If forecasting is selected, it generates \n",
    "    predictions over a specified horizon and optionally uses fine-tuning steps. \n",
    "    If anomaly detection is selected, it identifies anomalies in the data.\n",
    "\n",
    "    :param file_name: The name of the dataset to analyze. \n",
    "\n",
    "    :param method: The analysis method to use. Must be one of ['forecast', 'anomaly_detection']:\n",
    "                   - 'forecast': Predicts future values based on historical data.\n",
    "                   - 'anomaly_detection': Detects anomalies in the data.\n",
    "\n",
    "    :param horizon: (Optional) The forecast horizon, i.e., the number of future steps to predict.\n",
    "                    Only applicable when `method='forecast'`. Default is 0.\n",
    "\n",
    "    :param ftSteps: (Optional) The number of fine-tuning steps to apply during forecasting.\n",
    "                    Only applicable when `method='forecast'`. Default is 0.\n",
    "\n",
    "    :return: A JSON string containing the results of the analysis. The structure of the output depends on\n",
    "             the selected method:\n",
    "             - For `forecast`, it includes forecasted values and a visualization.\n",
    "             - For `anomaly_detection`, it includes detected anomalies and a visualization.\n",
    "             If an error occurs, the returned JSON contains an error message.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.getenv(\"TIME_GEN_ENDPOINT\") is None or os.getenv(\"TIME_GEN_KEY\") is None:\n",
    "        if method == 'forecast':\n",
    "            return \"./figures/Intrusion_Attempts_forecast_plot.png\"\n",
    "        else:\n",
    "            return \"./figures/Incident_Detection_Rate_anomalies_plot.png\"\n",
    "    \n",
    "    nixtla_client = NixtlaClient(\n",
    "        base_url=os.getenv(\"TIME_GEN_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"TIME_GEN_KEY\"),\n",
    "    )\n",
    "\n",
    "    if file_path is not None:\n",
    "        file_path = file_path if file_path.endswith(\n",
    "            'csv') else f'./data/{file_path}.csv'\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Initialize variables\n",
    "        horizon_int = None\n",
    "        ftSteps_int = None\n",
    "\n",
    "        try:\n",
    "            horizon_int = int(horizon)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            return f\"Error converting 'horizon': {e}\"\n",
    "\n",
    "        try:\n",
    "            ftSteps_int = int(ftSteps)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            return f\"Error converting 'ftSteps': {e}\"\n",
    "\n",
    "        if ftSteps is None:\n",
    "            ftSteps_int = 0\n",
    "\n",
    "        try:\n",
    "            if method == 'forecast':\n",
    "                forecast_df = nixtla_client.forecast(\n",
    "                    df=df,\n",
    "                    h=horizon_int,\n",
    "                    finetune_steps=ftSteps_int,\n",
    "                    time_col=\"timestamp\",\n",
    "                    target_col=\"value\",\n",
    "                )\n",
    "\n",
    "                fig = nixtla_client.plot(\n",
    "                    df=df, forecasts_df=forecast_df, time_col=\"timestamp\", target_col=\"value\"\n",
    "                )\n",
    "\n",
    "                ax = fig.axes[0]\n",
    "                ax.legend([\"Actual Values\", \"Forecasted Values\"],\n",
    "                          loc=\"upper right\", bbox_to_anchor=(1.14, 1), borderaxespad=0)\n",
    "                ax.set_title(f\"{file_name}: Forecasted vs Actual Values\", fontsize=18,\n",
    "                             fontweight=\"bold\", color=\"teal\", pad=15)\n",
    "\n",
    "                fig_name = f\"./figures/{file_name}_forecast_plot.png\"\n",
    "                fig.savefig(fig_name, dpi=300)\n",
    "\n",
    "                return fig_name\n",
    "            elif method == \"anomaly_detection\":\n",
    "                anomalies_df = nixtla_client.detect_anomalies(\n",
    "                    df,\n",
    "                    time_col=\"timestamp\",\n",
    "                    target_col=\"value\",\n",
    "                    freq=\"D\",\n",
    "                )\n",
    "                anomalies_df = anomalies_df.rename(columns={\n",
    "                    \"TimeGEN\": \"TimeGPT\",\n",
    "                    \"TimeGEN-lo-99\": \"TimeGPT-lo-99\",\n",
    "                    \"TimeGEN-hi-99\": \"TimeGPT-hi-99\"\n",
    "                })\n",
    "\n",
    "                fig = nixtla_client.plot(\n",
    "                    df, anomalies_df, time_col=\"timestamp\", target_col=\"value\")\n",
    "\n",
    "                ax = fig.axes[0]\n",
    "                ax.legend([\"Actual Values\", \"TimeGPT\", \"TimeGPT_level_99\", \"TimeGPT_anomalies_level_99\"],\n",
    "                          loc=\"upper right\", bbox_to_anchor=(1.21, 1), borderaxespad=0)\n",
    "                ax.set_title(f\"{file_name}: Anomalies on Actual Values\", fontsize=18,\n",
    "                             fontweight=\"bold\", color=\"teal\", pad=15)\n",
    "\n",
    "                fig_name = f\"./figures/{file_name}_anomalies_plot.png\"\n",
    "                fig.savefig(fig_name, dpi=300)\n",
    "\n",
    "                return fig_name\n",
    "            else:\n",
    "                return \"Invalid method specified.\"\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "    else:\n",
    "        return \"No data file provided.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_data(\"./data/intrusion_attempts_20250105_095639.csv\", 'forecast', horizon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_data(\"./data/Incident Detection Rate.csv\", 'anomaly_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "logging.getLogger('azure.core.pipeline.policies.http_logging_policy').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'analyze_data', 'description': 'Analyze a dataset using the specified analysis method (forecasting or anomaly detection).', 'parameters': {'type': 'object', 'properties': {'file_path': {'type': 'string', 'description': 'No description'}, 'method': {'type': 'string', 'description': \"The analysis method to use. Must be one of ['forecast', 'anomaly_detection']:\"}, 'horizon': {'type': ['integer', 'null'], 'description': '(Optional) The forecast horizon, i.e., the number of future steps to predict.'}, 'ftSteps': {'type': ['integer', 'null'], 'description': '(Optional) The number of fine-tuning steps to apply during forecasting.'}}, 'required': ['file_path', 'method']}}}]\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Set, Callable\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "\n",
    "user_functions: Set[Callable[..., Any]] = {analyze_data}\n",
    "functions = FunctionTool(functions=user_functions)\n",
    "print(functions.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.chained:DefaultAzureCredential acquired a token from AzureCliCredential\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_8ac0MkOHkYgiVUkA1EDSmyUV\n"
     ]
    }
   ],
   "source": [
    "data_analyzer = project_client.agents.create_agent(\n",
    "    model=os.environ[\"CHAT_MODEL\"],\n",
    "    name=\"data_analyzer\",\n",
    "    description=\"An agent that analyzes data using forecasting or anomaly detection.\",\n",
    "    instructions=\"Hello, you are helpful assistant.\",\n",
    "    tools=functions.definitions,\n",
    "    # Parameters\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    # Metadata\n",
    "    metadata={\"group\": \"internet_threat_analysis\"},\n",
    ")\n",
    "\n",
    "print(f\"Created agent, agent ID: {data_analyzer.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message_1 = project_client.agents.create_message(\n",
    "    thread_id=thread.id, role=\"assistant\", content=\"\"\"The intrusion attempts data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/intrusion_attempts_20250116_110658.csv.\n",
    "    \n",
    "    The incident detection data has been successfully fetched and saved as a CSV file. You can find it at the following path: ./data/incident_detection_rate_20250116_110539.csv\n",
    "    \"\"\"\n",
    ")\n",
    "message_2 = project_client.agents.create_message(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Hello, create a 10-day forecast using the intrusion attempts data. And detect anomalies in the incident detection data.\"\n",
    ")\n",
    "\n",
    "# Create and process assistant run in thread with tools\n",
    "run = project_client.agents.create_run(\n",
    "    thread_id=thread.id, assistant_id=data_analyzer.id)\n",
    "print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        if not tool_calls:\n",
    "            print(\"No tool calls provided - cancelling run\")\n",
    "            project_client.agents.cancel_run(\n",
    "                thread_id=thread.id, run_id=run.id)\n",
    "            break\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    print(f\"Executing tool call: {tool_call}\")\n",
    "                    output = functions.execute(tool_call)\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(\n",
    "                            tool_call_id=tool_call.id,\n",
    "                            output=output,\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "        print(f\"Tool outputs: {tool_outputs}\")\n",
    "        if tool_outputs:\n",
    "            project_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "    print(f\"Current run status: {run.status}\")\n",
    "\n",
    "print(f\"Run completed with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import helper\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "display(Markdown(helper.get_conversation_md(messages)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
